# AGENTS

Краткие ориентиры для agenta/оператора по работе с проектом.

## Что делает сервис
- Мониторит Telegram‑каналы/чаты, ищет сообщения по пользовательским запросам (1–3 слова, иногда больше), пересылает совпадения целевому пользователю.
- Запросы могут состоять из нескольких независимых частей (через запятую), возможны обязательные слова с префиксом `+`.
- Работает на слабом железе (ARM Cortex‑A7 ~1.3 GHz, 512 MB RAM); приоритет — малое потребление памяти, быстрота поиска.

## Основные модули
- `service/search_engine.py` — токенизация, fuzzy‑/tf‑idf поиск по окнам предложений, поддержка независимых клауз и `+`‑обязательных токенов.
- `service/db/database.py` + `service/db/models.py` — SQLite, кеши поисковых данных (`QuerySearchEntry`, `ChannelSearchContext`), `slots=True` и tuple для экономии RAM.
- `service/main_handler.py` — обработка входящих сообщений, дедупликация, вызов поиска, пересылка результатов.
- `service/telegram_client.py` — инициализация Telethon‑клиента (вынесено из config для уменьшения импорта).
- `service/cache.py` — TTL‑кеш с опциональным `max_items` и фоновым очистителем.

## Как работает поиск (коротко)
- Токенизация/лемматизация с кешированием (`Cache`), стоп‑слова отсекаются, используется `rapidfuzz` для сравнения токенов.
- Без жёсткого порядка слов: матч bag‑of‑tokens с ограничением «один текстовый токен → максимум один запросный токен», штраф за разброс (компактность окна).
- Быстрый путь: если все запросные токены встретились подряд в любом порядке — скор 100.
- TF‑IDF второй сигнал: на основе токенов запросов строится IDF, косинусное сходство усиливает результат для редких слов.
- Запросы заранее парсятся в клаузы (части через запятую). Каждая клаузa ищется отдельно; итоговый скор — минимум по клаузаm (все должны совпасть).
- `+word` делает токен обязательным в клаузе; без него окно сразу отсекается.

## RAM/перфоманс установки
- Токенизационный кеш: TTL 2 часа, `max_items=2000` — держит нормализованные токены текстов.
- Дедуп‑кеши в `main_handler`: ограничены по элементам, чтобы не разрастались.
- `dataclass(..., slots=True)` и `tuple` в моделях поиска снижают per‑object overhead.
- Не запускать лишние тяжёлые фоновые задачи; писать на SD только если нужно (SQLite и кеши работают в памяти).

## Типовой запуск/отладка
- Требуются env: `TELEGRAM_APP_ID`, `TELEGRAM_API_HASH`, `TARGET_USER`, опционально сетевые таймауты (см. `service/config.py`).
- Библиотеки: `telethon`, `rapidfuzz`, `nltk`, `pymorphy3`. Для тестов нужен `pytest`/`unittest` (в окружении может не стоять).
- При старте база/кеши прогружают запросы, токенизируют их один раз и строят tf‑idf для каналов.

## На что обращать внимание
- Любые изменения в поиске — проверять, что порядок слов не обязателен, но компактность влияет на скор.
- Если добавляется новая логика запросов, обновлять парсер в `parse_query_phrase` и модели `ClauseSpec`.

